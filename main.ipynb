{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import cv2\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 22:09:56.845452: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-25 22:09:56.849174: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(\"model/yolo.h5\")\n",
    "detector.loadModel()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "img_array = cv2.imread(\"media/images/4.jpg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "custom = detector.CustomObjects(person=True)\n",
    "\n",
    "detections = detector.detectObjectsFromImage(\n",
    "    custom_objects=custom,\n",
    "    input_image=img_array,\n",
    "    # output_image_path=\"media/output_images/image_new.jpg\",\n",
    "    minimum_percentage_probability=30,\n",
    "    input_type=\"array\",\n",
    "    output_type=\"array\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[[2, 0, 0],\n         [2, 0, 0],\n         [2, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        [[2, 0, 0],\n         [2, 0, 0],\n         [2, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        [[2, 0, 0],\n         [2, 0, 0],\n         [2, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        ...,\n \n        [[1, 0, 4],\n         [1, 0, 2],\n         [1, 0, 4],\n         ...,\n         [2, 0, 0],\n         [2, 0, 0],\n         [2, 0, 0]],\n \n        [[0, 0, 1],\n         [0, 0, 0],\n         [0, 0, 1],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n \n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0],\n         ...,\n         [0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]]], dtype=uint8),\n [{'name': 'person',\n   'percentage_probability': 99.6704638004303,\n   'box_points': [40, 26, 177, 183]}])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detections)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"media/output_images/image_new_array.jpg\", detections[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(\"media/input_video/video_2.mp4\")\n",
    "\n",
    "while vid.isOpened():\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = vid.read()\n",
    "    print(ret)\n",
    "\n",
    "    if ret:\n",
    "        cv2.imwrite(f\"media/images_from_video/__{uuid4()}.jpg\", frame)\n",
    "\n",
    "    # while not ret:\n",
    "    #     print(\"Can't receive frame. Retrying ...\")\n",
    "    #     vid.release()\n",
    "    #     vid = cv2.VideoCapture(\"media/input_video/video_2.mp4\")\n",
    "    #     ret, frame = vid.read()\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    vid.release()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
